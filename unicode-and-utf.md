# Unicode 与 UTF 的关系

## Unicode的由来
为了在计算机中表示我们平时写的字符（如数字0、1、2，罗马字母a、b、c、A、B、C，标点符号，汉字等），需要对这些字符进行编码，即在计算机中用特定的数字标识这些字符。

最初，计算机在美国被使用时，由于英文的只有26个字母，算上大小写即其他符号，字符数也不多，于是只需要7个bit（可表示128个字符）就足够了。于是出现了最初的ASCII编码，用一个字节的低7位表示，其最高位置为0。

後来，欧洲开始使用计算机，发现不同的字符数超过了128个（如法文、德文、俄文中的一些字符），只用7bit无法表示完全。于是出现了ISO编码，该编码中每个字符也用1个字节表示，且最高位可为1，用来标识新增的欧洲国家文字的字母（最高位为0时，含义与ASCII编码相同）。

再後来，计算机在全世界普遍流行後，全世界的文字用1个字节（最多表示256个不同的字符）根本无法表示，尤其是像汉字这种含有几万十几万个不同字符的文字，以及一些常用的标志符、表情符号等。

为了统一世界范围内所有字符的编码，于是出现了Unicode（统一码）编码方案。

## UTF
Unicode只是一种将计算机中的数字与字符对应起来的编码方案，但是具体如何在计算机中使用这套编码方案（如用几个字节表示一个字符，每个字符所用字节数是否相同，若所用字节数不同则如何确定单个字符的字节边界等），还需要更为细致的实现方案。

UTF(Unicode Transformation Format，直译为Unicode转换格式) ，就是在计算机中使用Unicode表示字符的一套实施方案。



#### 参考文档：
1. [utf-8和Unicode的区别](https://www.cnblogs.com/dhsz/p/7737480.html)
